---
title: "Variant Calling: Indels and Copy Number Variants"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: false
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(data.table)
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)
```


## Workshop Learning Objectives {data-progresive=FALSE}

### Background

Today we will be calling insertions and deletions (indels) and copy number variants from short-read exome sequencing data. The data we are using was generated by the [Genome In A Bottle Consortium](https://www.nist.gov/programs-projects/genome-bottle). The Genome In A Bottle Consortium have curated gold-standard variant calls from several germline DNA samples using numerous sequencing methods and variant callers, with the aim of providing a resource for which the bioinformatic community can benchmark their variant calling pipelines. 

In this workshop, we will work with exome capture data from NA12878. This is a genomic DNA sample derived from the GM12878 cell line. The libraries were prepared using the Nextera Rapid Capture library preparation kit and sequenced on an Illumina HiSeq2000 instrument with 100bp PE reads.

### By the end of this workshop you should be able to:

* Perform quality control on exome-capture DNA sequencing data and resolve sequence quality issues
* Describe the key steps involved in generating an analysis-read BAM file as per the GATK best practices
* Identify germline small insertions, deletions and copy number variants using standard tools


**Note: You will be required to submit an annotated RMarkdown notebook for assessment following this workshop (due: X). As you participate in todays workshop we suggest you begin drafting a notebook with relevant code and annotations**

TODO

3) Trim adaptors and poor quality sequences - TrimGalore - DONE
4) GATK preprocessing steps from reads to analysis ready BAM - GATK and BWA
5a) Call variants with GATK Haplotype caller - GATK
5b) Call variants with Strelka2 default parameters - Strelka2
6) Annotate variants with VEP and/or SNPeff - SNPeff
7) Visualise with IGV and correlate with clinical information - IGV 

Write the R code required to add two plus two:

## Sequence QC, alignment and post-alignment processing

### Raw sequence quality control

Our first task is to perform some initial quality control. For this, we can use the [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) tool. 

**Exercise:**
Write and execute a bash script that contains a loop to execute fastqc on all the sequencing reads and have the reports placed in a directory named `fastqc_reports`. *Hint: You will need to make the fastqc_reports directory and load a fastqc module using the `module load` command.*

<details><summary>**Solution**</summary>

```{bash fastqc, eval = FALSE, echo =  TRUE}
#!/bin/bash
mkdir fastqc_reports
module load fastqc/0.11.9
for $f in ./PATH_TO_READS/*.fastq.gz 
do
fastqc $f --outdir ./fastqc_reports
done
```

</details>




In the `fastqc_reports` directory you will find four `.html` reports. Each corresponds to either forward or reverse sequences, sequenced across lane 1 or 2. 

**Exercise:**
In an RMarkdown notebook, insert but don't execute the code above. Open up each file and explore the various parameters. Comment on which parameters are flagged as "warning" and "failed". Take some screengrabs of the relevent plots and insert them into your notebook. *Hint: You will need to link to the file, for more information see [this tutorial](https://www.earthdatascience.org/courses/earth-analytics/document-your-science/add-images-to-rmarkdown-report/)*

```{r MC1}
  quiz(caption = "Concept Check",
    question("Which of the following QC parameters were marked as failed?",
    answer("Per base sequence quality"),
    answer("Per tile seqeunce quality"),
    answer("Per base sequence content", correct = TRUE),
    answer("Per sequence GC content", correct = TRUE),
    correct = "Well done!", allow_retry = TRUE
  ), 
   question("FastQC has revealed a sequence bias in the first 15bp of the read. Which of the following could explain this bias?",
    answer("Random Hexamer Priming"),
    answer("Contamination"),
    answer("Tagmentation-based library preparation", correct = TRUE), correct = "That's right, library preparation methods that use tagmentation for fragmentation have an inherent sequence composition bias that affects the first 15 nucleotides of reads. This does not adversely affect downstream processing and should not be trimmed."
  ))
```


### Adaptor and quality trimming

Our initial fastQC reports indicated that sequencing adapters remain on the reads. We can remove these adaptors and trim poor quality bases using the [TrimGalore! tool](https://github.com/FelixKrueger/TrimGalore/blob/master/Docs/Trim_Galore_User_Guide.md). The TrimGalore tool is a wrapper of cutadapt and fastqc and is used for removing sequencing adaptors and quality trimming reads. This is an important step as both adaptors and poor quality sequencing reads can adversely affect mapping and reduce the quality of variant calls. 

TrimGalore! follows a four step process:

1. Trimming of low quality bases from the reads.
2. Sequencing adapters are identified and removed. TrimGalore! will search for predefined adapters (Illumina, Small RNA, Nextera), however you can direct the tool to search for custom adapters.
3. Removal of short sequences
4. Specialised trimming (user specified, ie. hard-trimming)

**Exercise:**
Using the user guide linked above, construct a bash script to trim adaptors and poor quality bases. Include in your command the output directory: `trimmed_reads`, Save files in a directory called `trimmed_reads` and flags to run fastqc and set the number of cores to 2.

<details><summary>**Solution**</summary>

```{bash trimgalore, eval = FALSE, echo =  TRUE}
#!/bin/bash
module load trim_galore/0.5.0
trim_galore --paired --output_dir trimmed_reads --fastqc --cores 2  ./reads/NIST7035_TAAGGCGA_L001_R1_001.fastq.gz ./reads/NIST7035_TAAGGCGA_L001_R2_001.fastq.gz \
./reads/NIST7035_TAAGGCGA_L002_R1_001.fastq.gz ./reads/NIST7035_TAAGGCGA_L002_R2_001.fastq.gz 
```

</details>

### Sequencing alignment and post-alignment processing

In the interests of time, we have performed sequence alignment and post-alignment processing for you. This included:

1. Indexing of the human genome with `bwa index`
2. Aligning reads to the genome with `bwa mem`
3. Assessed mapping rate using `samtools flagstat`, converted .sam file to .bam files using `samtools view`, sorted by coordinates using `samtools sort` and indexed using `samtools index`

<details><summary>**Code**</summary>

```{bash bwa-samtools, eval = FALSE, echo =  TRUE}
#!/bin/bash
module load bwa/0.7.17-gcc5
module load samtools/1.9
while read name
do
bwa mem \
/home/lfennell/bk32_scratch/references/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta.gz \
./trimmed_reads/${name}R1_001_val_1.fq.gz \
./trimmed_reads/${name}R2_001_val_2.fq.gz \
-t 5 \
-R '@RG\tID:$name\tSM:NA12878\tPL:illumina\tLB:NA12878_lib' \
> ./bam_files/$name.sam;
samtools view -b bam_files/$name.sam |\
samtools sort > bam_files/$name.sorted.bam
samtools index bam_files/$name.sorted.bam
done < bam_files/samplelist.txt
for $f in bam_files/*.sorted.bam
do
samtools flagstat -O $f > /bam_files/${f}.txt
done

```

</details>

<br>

4. Merged the alignments from lane 1 and lane 2 with `picard MergeSamFiles`. Note we merge these after alignment as we can inspect raw sequences and alignment statistics and identify any lane specific anomalies. 

<details><summary>**Code**</summary>
```{bash picard-merge, eval = FALSE, echo =  TRUE}
#!/bin/bash
module load gatk/4.2.5.0
java -jar /home/lfennell/bk32_scratch/IndelWorkshop/NA12878_GIAB_WES/Tools/picard.jar MergeSamFiles \
I=bam_files/NIST7035_TAAGGCGA_L001_.sorted.bam \
I=bam_files/NIST7035_TAAGGCGA_L002_.sorted.bam \
O=bam_files/NIST7035_TAAGGCGA.merged.sorted.bam
```
</details>

<br>

5. Marking PCR duplicates with `GATK MarkDuplicatesSpark`, which is an implementation of Picard's MarkDuplicates that can be run in parallel across multiple cores for efficiency.

<details><summary>**Code**</summary>

```{bash MarkDuplicatesSpark, eval = FALSE, echo =  TRUE}
#!/bin/bash
module load gatk/4.2.5.0
gatk MarkDuplicatesSpark \
-I bam_files/NIST7035_TAAGGCGA.merged.sorted.bam \
-O bam_files/NIST7035_TAAGGCGA.dups.merged.sorted.bam \
-M bam_files/NIST7035_TAAGGCGA.dupMetrics.txt \
--conf 'spark.executor.instances=5' \
--conf 'spark.executor.cores=5' \
--conf 'spark.executor.memory=8G'
```

</details>

<br>


6. Recalibrated base quality scores with `GATK BaseRecalibrator` and `ApplyBQSR`


<details><summary>**Code**</summary>

```{bash BaseRecal-ApplyBQSR, eval = FALSE, echo =  TRUE}
#!/bin/bash
module load gatk/4.2.5.0
gatk BaseRecalibrator \
-I bam_files/NIST7035_TAAGGCGA.dups.merged.sorted.bam \
-R /home/lfennell/bk32_scratch/references/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta.gz \
--known-sites /home/lfennell/bk32_scratch/references/GRCh38/Homo_sapiens_assembly38.known_indels.vcf \
--known-sites /home/lfennell/bk32_scratch/references/GRCh38/Homo_sapiens_assembly38.dbsnp138.vcf \
-O bam_files/recal_data.table

gatk ApplyBQSR \
-R /home/lfennell/bk32_scratch/references/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta.gz \
-I bam_files/NIST7035_TAAGGCGA.dups.merged.sorted.bam \
--bqsr-recal-file bam_files/recal_data.table \
-O bam_files/NIST7035_TAAGGCGA.recal.dups.merged.sorted.bam
```

</details>

<br>

**Exercise:**
In small groups, each research a specific function used in the code above by referencing the relevant documentation. Comment on what the function does and why it is important. Be sure to include these explanations in your RMarkdown notebook.

```{r MC2}
  quiz(caption = "Concept Check",
    question("Consider the role of the MarkDuplicates tool in bioinformatic workflows. Which of the following scenarios would filtering be inappropriate? - You may need to research each sequencing method.",
    answer("RNA-sequencing", correct = TRUE),
    answer("Reduced-Representation Bisulphite Sequencing", correct = TRUE),
    answer("Whole Genome Sequencing"),
    answer("Whole Exome Sequencing"),
    correct = "Well done! Both of these approaches are non-random and will generate reads that are identical, but arose via biology rather than through the library preparation process", allow_retry = TRUE
  ), 
   question("We used bwa-mem for aligning our sequencing reads. If our reads were ~50bp in length which bwa algorithm would you use? - You may need to consult the bwa documentation",
    answer("bwa-mem"),
    answer("bwa-sw"),
    answer("bwa-backtrack", correct = TRUE), correct = "That's right, both bwa-mem and bwa-sw were designed to work with sequences >70bp and <1mbp."
  ))
```


## Variant calling

### Strelka2

Now we have generated an analysis ready alignment we can proceed to variant calling. For germline samples, there are several tools that we can use to call indels. These include GATK's haplotypecaller, Illumina's Strelka2 and Google's DeepVariant. Each of these tools uses different methodologies and each has distinct advantages and disadvantages. One advantage of Strelka2 is that it requires relatively few computational resources and is fast. We will use Strelka2 to call candidate variants in the NA12878 exome.

**Exercise:**
Consult the [strelka2 documentation](https://github.com/Illumina/strelka/blob/v2.9.x/docs/userGuide/quickStart.md) and design a command that will call variant using 2 threads. Have the output deposited into a folder called `variants`. *Note: Strelka2 and the reference genome can be found in the tools and references sub directories, respectively*

<details><summary>**Solution**</summary>

```{bash, eval = FALSE, echo = TRUE}
#!/bin/bash
/PATH_TO_STRELKA/bin/configureStrelkaGermlineWorkflow.py \
--bam bam_files/NIST7035_TAAGGCGA.recal.dups.merged.sorted.bam \
--referenceFasta /PATH_TO_REFERENCE/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta.gz \
--runDir variants
variants/runWorkflow.py -m local -j 2
```

</details>

<br>
Let's explore the output vcf file which can be found in `variants/results/variants`. vcftools and bcftools contain several convienience functions that can be used to quickly query vcf files.

**Exercise:**
Use bcftools to generate statistics from the vcf file. 


```{r print-limit, exercise=TRUE, exercise.eval=TRUE}
mtcars
```

```{r print-limit-hint}
head(mtcars)
```

### Quiz

*You can include any number of single or multiple choice questions as a quiz. Use the `question` function to define a question and the `quiz` function for grouping multiple questions together.*

Some questions to verify that you understand the purposes of various base and recommended R packages:

## Assessment
